# æœ¬åœ°æœç´¢å¼•æ“ â€” AI ç¼–ç  Prompt

> å°†æ­¤ Prompt ç›´æ¥å–‚ç»™ AI ç¼–ç åŠ©æ‰‹ï¼Œå³å¯æŒ‰ç…§è§„èŒƒé€æ¨¡å—å®ç°é¡¹ç›®ã€‚  
> æŒ‰ Phase é¡ºåºæ‰§è¡Œï¼Œæ¯ä¸ª Phase å®Œæˆåç¼–è¯‘éªŒè¯å†è¿›å…¥ä¸‹ä¸€ä¸ªã€‚

---

## å…¨å±€çº¦æŸ

```yaml
é¡¹ç›®å: local-search-engine
è¯­è¨€: Java 21 (LTS)
æ„å»º: Gradle 8.6 (Kotlin DSL)
åŒ…å: com.localengine
é£æ ¼:
  - æ³¨é‡Šå¿…é¡»ä¸­æ–‡
  - å˜é‡å‘½åè‹±æ–‡ï¼Œé©¼å³°å‘½å
  - æ¯ä¸ªç±»é¡¶éƒ¨ Javadoc è¯´æ˜èŒè´£
  - å¸¸é‡æå–åˆ° Constants.java
  - ä¸ä½¿ç”¨ Lucene/Elasticsearch ç­‰æœç´¢æ¡†æ¶
  - ä¸ä½¿ç”¨å®éªŒæ€§ç‰¹æ€§
```

---

## Phase 1: å­˜å‚¨åŸºç¡€

### Prompt 1.1 â€” ç¼–ç å™¨
```
å®ç°ä¸¤ä¸ªç¼–ç å·¥å…·ç±»ï¼š

1. VarIntCodecï¼ˆå˜é•¿æ•´æ•°ç¼–è§£ç å™¨ï¼‰ï¼š
   - writeVarInt(int value, OutputStream out)
   - readVarInt(InputStream in) â†’ intï¼Œæµç»“æŸè¿”å› -1
   - writeVarInt(int value, ByteBuffer buf)
   - readVarInt(ByteBuffer buf) â†’ int
   - writeVarLong / readVarLong (long ç‰ˆæœ¬)
   - varIntSize(int value) â†’ é¢„è®¡å­—èŠ‚æ•°
   - ç¼–ç è§„åˆ™ï¼šæ¯å­—èŠ‚ 7 ä½æœ‰æ•ˆï¼Œæœ€é«˜ä½ä¸ºç»­æ¥æ ‡å¿—

2. DeltaCodecï¼ˆDelta ç¼–ç å™¨ï¼‰ï¼š
   - encode(int[] values) â†’ int[] deltas
   - decode(int[] deltas) â†’ int[] values
   - encodeDeltaVarInt(int[] values, OutputStream out)
   - decodeDeltaVarInt(int count, InputStream in) â†’ int[]
   - estimateEncodedSize(int[] values) â†’ int

è¦æ±‚ï¼šè¾“å…¥å¿…é¡»æ˜¯éè´Ÿå•è°ƒé€’å¢åºåˆ—ã€‚å†™å®Œååˆ›å»º CodecTest å•å…ƒæµ‹è¯•ã€‚
```

### Prompt 1.2 â€” æ–‡ä»¶æ ¼å¼è¯»å†™å™¨
```
åŸºäº VarIntCodec å’Œ DeltaCodec å®ç°ä¸‰ç»„æ–‡ä»¶è¯»å†™å™¨ã€‚

1. DictionaryWriter / DictionaryReader
   æ–‡ä»¶æ ¼å¼ï¼šHeader(magic 0x4C534449 + version 1 + termCount) + N æ¡ TermEntry + CRC32
   TermEntry = termLen(VarInt) + termBytes(UTF-8) + docFreq(VarInt) + postingsOffset(8B) + positionsOffset(8B)
   - Writer: éªŒè¯ term ä¸¥æ ¼é€’å¢ï¼Œclose åè°ƒç”¨ patchTermCount(File) å›å¡« header
   - Reader: new DictionaryReader(File) æ—¶å…¨é‡åŠ è½½åˆ° TreeMap
   - Reader æä¾›: lookup(term), prefixSearch(prefix), allTerms(), contains(term), getTermCount()

2. PostingsWriter / PostingsReader
   æ–‡ä»¶æ ¼å¼ï¼šHeader(magic 0x4C535049 + version) + N ä¸ª PostingList
   PostingList = docCount(VarInt) + skipCount(VarInt) + SkipEntries + DeltaDocIds(VarInt) + TermFreqs(VarInt)
   SkipEntry = skipDocId(4B) + skipOffset(4B)ï¼Œæ¯ 128 ä¸ª docId æ’ä¸€ä¸ª
   - Writer: writePostingList(int[] docIds, int[] termFreqs) â†’ long offset
   - Reader: ä½¿ç”¨ RandomAccessFileï¼ŒreadPostingList(long offset) â†’ PostingList record
   - PostingList record æä¾›: size(), docId(i), termFreq(i), docIds(), termFreqs()

3. PositionWriter / PositionReader
   æ–‡ä»¶æ ¼å¼ï¼šHeader(magic 0x4C535053 + version) + N ä¸ª PositionBlock + CRC32
   PositionBlock = docCount(VarInt) + [docId(VarInt) + posCount(VarInt) + positions(delta-VarInt)] Ã— docCount
   - Writer: writePositions(int[] docIds, int[][] positions) â†’ long offset
   - Reader: readPositions(offset) â†’ Map<Integer, int[]>, readPositionsForDoc(offset, docId) â†’ int[]

4. SegmentMeta â€” JSON åºåˆ—åŒ–çš„æ®µå…ƒæ•°æ®
   å­—æ®µï¼šsegmentId, docCount, termCount, sizeBytes, status(ACTIVE/MERGING/DELETED), level, createTime
   - writeTo(File) / readFrom(File) ä½¿ç”¨ Jackson

å†™å®Œååˆ›å»º StorageRoundTripTestï¼Œæµ‹è¯•å†™å…¥â†’è¯»å–çš„æ­£ç¡®æ€§ï¼ŒåŒ…å«å‰ç¼€æŸ¥è¯¢æµ‹è¯•ã€‚
```

---

## Phase 2: ç´¢å¼•æµæ°´çº¿

### Prompt 2.1 â€” æ–‡æ¡£æ¨¡å‹ä¸å…ƒæ•°æ®
```
1. Document recordï¼š
   (int docId, Path path, String extension, long sizeBytes, Instant mtime, DocType docType, int tokenCount)
   DocType æšä¸¾: CODE, NOTE, DOC, DATA, CONFIG, OTHER
   å·¥å‚æ–¹æ³• ofFile(int docId, Path path, List<Path> notePaths) â€” æ ¹æ®æ‰©å±•åå’Œè·¯å¾„æ¨æ–­ docType
   æ–¹æ³• withTokenCount(int count) è¿”å›æ–°å®ä¾‹

2. DocumentTable (SQLite)ï¼š
   è¡¨ç»“æ„ï¼šdoc_id INTEGER PK, path TEXT UNIQUE, extension TEXT, size_bytes INTEGER, mtime TEXT, doc_type TEXT, token_count INTEGER
   å¯ç”¨ WAL æ¨¡å¼
   æ–¹æ³•ï¼šinsert, update(docId, size, mtime, tokenCount), deleteByPath â†’ Optional<Integer>, findByPath, findById
   è¿‡æ»¤æ–¹æ³•ï¼ˆå‡è¿”å› List<Integer>ï¼‰ï¼šfindDocIdsByExtension, findDocIdsByType, findDocIdsByMtimeRange, findDocIdsBySizeRange, findDocIdsByPathPrefix
   ç»Ÿè®¡æ–¹æ³•ï¼šgetTotalDocCount, getAverageDocLength, nextDocId

å†™å®Œåæµ‹è¯• CRUD å’Œè¿‡æ»¤æ–¹æ³•ã€‚
```

### Prompt 2.2 â€” åˆ†è¯å™¨
```
SPI æ¥å£ Tokenizerï¼štokenize(String text) â†’ List<Token>
Token record: (String term, int position, int startOffset, int endOffset)

å®ç°ï¼š
1. EnglishTokenizer(boolean enableStopWords)ï¼šéå­—æ¯æ•°å­—åˆ†å‰² â†’ å°å†™ â†’ è¿‡æ»¤ lengthâ‰¤1 â†’ å¯é€‰åœç”¨è¯
2. StopWordsï¼šé™æ€ Set.of("the","a","an","is","are","was","were","be","been","has","have","had","do","does","did","will","would","could","should","may","might","can","and","or","but","not","in","on","at","to","for","of","with","by","from","as","into","it","its","this","that","which","if","so","no","up","out","all","just","also","very")
3. BigramTokenizerï¼šæ£€æµ‹è¿ç»­ CJK å­—ç¬¦ â†’ ä¸¤ä¸¤åˆ‡åˆ†ï¼ˆå•å­—ç¬¦ä¹Ÿè¾“å‡ºï¼‰ï¼Œå¿½ç•¥é CJK
4. CompositeTokenizer(boolean enableStopWords)ï¼šæŒ‰å­—ç¬¦ç±»å‹åˆ†æ®µï¼ŒCJK æ®µç”¨ BigramTokenizerï¼Œå…¶ä½™ç”¨ EnglishTokenizerï¼Œå…¨å±€ position é€’å¢

CJK æ£€æµ‹ï¼šCharacter.UnicodeScript.of(ch) âˆˆ {HAN, HIRAGANA, KATAKANA, HANGUL}

å†™å®Œåæµ‹è¯•ï¼šä¸­è‹±æ··åˆåˆ†è¯ã€åœç”¨è¯è¿‡æ»¤ã€position è¿ç»­æ€§ã€‚
```

### Prompt 2.3 â€” æ ¸å¿ƒç´¢å¼•ç»„ä»¶
```
1. FileCollectorï¼š
   æ„é€ ï¼šFileCollector(Set<String> supportedExtensions, List<Path> notePaths)
   æ–¹æ³•ï¼š
   - collectAll(List<Path> sourcePaths) â†’ List<FileInfo>
   - streamCollect(List<Path> sourcePaths, BlockingQueue<FileInfo> queue) â€” æµå¼ç‰ˆï¼Œéå†å®Œæ”¾ POISON pill
   FileInfo record: (Path path, long sizeBytes, Instant mtime, boolean isNote)
   é™æ€å¸¸é‡ POISON = new FileInfo(Path.of("__POISON__"), -1, Instant.EPOCH, false)
   è¿‡æ»¤é€»è¾‘ï¼šæŒ‰æ‰©å±•å + å¯è¯» + ééšè—

2. WAL (Write-Ahead Log)ï¼š
   æ„é€ ï¼šWAL(Path walDir)
   æ ¼å¼ï¼š[op(1B)] [timestamp(8B)] [pathLen(VarInt)] [path(UTF-8)] [mtime(8B)] [size(8B)]
   æ–¹æ³•ï¼šappendAdd/appendDelete/appendUpdate(path, mtime, size), checkpoint(), replay() â†’ List<WalEntry>
   WalEntry record: (WalOp op, Instant timestamp, String path, Instant mtime, long sizeBytes)
   WalOp: ADD=1, DELETE=2, UPDATE=3
   è¶…è¿‡ WAL_MAX_SIZE è½®è½¬

3. MemorySegmentï¼š
   ConcurrentHashMap<String, TermData> å­˜å‚¨å€’æ’
   TermData: docIds(IntList) + termFreqs(IntList) + positions(Map<Integer, IntList>)
   æ–¹æ³•ï¼šaddDocument(int docId, List<Token> tokens), flush(File segmentDir) â€” æ’åºå†™å…¥ dict/inv/pos ä¸‰æ–‡ä»¶
   å¹¶å‘ï¼šReadWriteLock ä¿æŠ¤ flushï¼ŒaddDocument æœŸé—´å…è®¸å¹¶å‘å†™

4. DiskSegmentï¼š
   æ„é€ ï¼šåŠ è½½ .meta + è¯å…¸å…¨é‡åˆ°å†…å­˜ + æ‰“å¼€ .inv/.pos RandomAccessFile
   æ–¹æ³•ï¼šgetPostings(term), prefixSearch(prefix), getPositions(term), getPositionsForDoc(term, docId), markDeleted(docId), isDeleted(docId), getDocFreq(term)
   å·²åˆ é™¤ docId ç”¨ ConcurrentHashMap.newKeySet() æƒ°æ€§æ ‡è®°

5. IndexManagerï¼š
   ç¼–æ’å…¨æµç¨‹ï¼šFileCollector â†’ producers â†’ BlockingQueue â†’ consumers â†’ MemorySegment â†’ flush â†’ DiskSegment
   æ–¹æ³•ï¼šbuildIndex(sourcePaths), rebuild(sourcePaths), flushMemorySegment(), recoverFromWal(), getActiveSegments(), getStatus()
   segments.gen æ–‡ä»¶è®°å½•æ´»è·ƒæ®µåˆ—è¡¨ï¼ˆåŸå­æ›¿æ¢å†™å…¥ï¼‰
```

---

## Phase 3: æŸ¥è¯¢å¼•æ“

### Prompt 3.1 â€” Query DSL
```
å®ç°è‡ªå®šä¹‰æŸ¥è¯¢ DSL çš„è¯æ³•åˆ†æå’Œè¯­æ³•è§£æã€‚

1. QueryNode (sealed interface)ï¼š
   TermQuery(term), PrefixQuery(prefix), PhraseQuery(List<String> terms),
   BooleanQuery(BoolOp op, left, right), NotQuery(child),
   FieldQuery(field, value), RangeQuery(field, from, to), SortDirective(field)
   BoolOp: AND, OR

2. QueryLexerï¼š
   è¾“å…¥å­—ç¬¦ä¸² â†’ List<LexToken>
   TokenType: TERM, PHRASE, FIELD, RANGE_SEP, LPAREN, RPAREN, AND, OR, NOT, MINUS, SORT, STAR, EOF
   å¤„ç†ï¼šåŒå¼•å·çŸ­è¯­ã€field:valueï¼ˆè¯†åˆ« path/ext/size/mtime/type/sortï¼‰ã€.. èŒƒå›´åˆ†éš”ã€å¸ƒå°”å…³é”®å­—ã€*å‰ç¼€

3. QueryParserï¼ˆé€’å½’ä¸‹é™ï¼‰ï¼š
   è¯­æ³•ï¼š
     query = clause { clause }ï¼ˆéšå¼ ANDï¼‰
     clause = [AND|OR|NOT|-] expression
     expression = group | phrase | field_expr | prefix | term
     group = '(' orExpr ')'    â† æ‹¬å·å†…æ”¯æŒ OR
     field_expr = FIELD (range | value)
   é”™è¯¯å¤„ç†ï¼šQueryParseException åŒ…å« positionã€queryString å’Œ suggestionï¼Œæ ¼å¼åŒ–è¾“å‡ºå¸¦ ^ æŒ‡ç¤ºä½ç½®

æµ‹è¯•ç”¨ä¾‹ï¼šç®€å•è¯é¡¹ã€çŸ­è¯­ã€å‰ç¼€ã€éšå¼ANDã€æ˜¾å¼ANDã€OR(æ‹¬å·å†…)ã€NOTã€-æ’é™¤ã€å­—æ®µè¿‡æ»¤ã€èŒƒå›´æŸ¥è¯¢ã€sortæŒ‡ä»¤ã€å¤æ‚ç»„åˆã€æœªé—­åˆå¼•å·é”™è¯¯ã€‚
```

### Prompt 3.2 â€” æŸ¥è¯¢æ‰§è¡Œ
```
1. BM25Scorerï¼š
   æ„é€ ï¼š(int totalDocs, double avgDocLength, double k1=1.2, double b=0.75)
   æ–¹æ³•ï¼šscore(int tf, int df, int docLength), computeIDF(int df), scoreMultiTerms(int[] tfs, int[] dfs, int docLen)
   å…¬å¼ï¼šIDF = ln((N-df+0.5)/(df+0.5)+1)ï¼ŒTFå½’ä¸€åŒ– = tf*(k1+1)/(tf+k1*(1-b+b*|D|/avgDL))

2. SnippetGeneratorï¼š
   æ„é€ ï¼š(int contextChars=80, int maxSnippets=3)
   æ–¹æ³•ï¼šgenerate(String content, Set<String> queryTerms, List<int[]> hitOffsets) â†’ List<Snippet>
   Snippet record: (String text, int lineNumber, int offset, List<HighlightSpan> highlights)
   é€»è¾‘ï¼šå®šä½å‘½ä¸­ â†’ Â±contextChars çª—å£ â†’ å¯¹é½è¯è¾¹ç•Œ â†’ åˆå¹¶é‡å  â†’ term å¯†åº¦æ’åº â†’ ANSI é«˜äº®

3. QueryEngineï¼š
   æ„é€ ï¼š(IndexManager indexManager)
   æ–¹æ³•ï¼šsearch(String queryString, int limit) â†’ SearchResult
   SearchResult record: (List<SearchHit> hits, int totalMatches, long elapsedMs, String query)
   SearchHit record: (Document document, double score, List<Snippet> snippets)
   æ‰§è¡Œï¼š
   - è§£æ AST â†’ éå†æ¯ä¸ª DiskSegment â†’ é€’å½’ evaluateNode
   - TermQuery: è¯» PostingList â†’ é€ doc BM25
   - PhraseQuery: å¤š PostingList æ±‚ docId äº¤é›† â†’ ä½ç½®éªŒè¯ pos[i+1]==pos[i]+1
   - BooleanQuery(AND): å·¦å³å­æ ‘äº¤é›†
   - BooleanQuery(OR): å¹¶é›†
   - NotQuery: æ’é™¤é›†
   - FieldQuery/RangeQuery: å§”æ‰˜ DocumentTable SQL
   - æœ€ç»ˆæ’åº (relevance/mtime/size) â†’ Top-N â†’ ç”Ÿæˆ Snippet
```

---

## Phase 4: CLI

### Prompt 4.1
```
ä½¿ç”¨ picocli å®ç° CLI ä¸»å‘½ä»¤ MainCommandï¼š

é¡¶å±‚é€‰é¡¹ï¼š--index-dir, --note-dir, --threads
å­å‘½ä»¤ï¼š
- index <path...>: è°ƒç”¨ IndexManager.buildIndex
- search "<query>" [--limit N] [--format text|json]: è°ƒç”¨ QueryEngine.searchï¼Œtext æ ¼å¼æ‰“å°è·¯å¾„/åˆ†æ•°/snippetï¼Œjson æ ¼å¼ç”¨ Jackson è¾“å‡º
- status: è°ƒç”¨ IndexManager.getStatus æ‰“å°ç»Ÿè®¡
- rebuild <path...>: è°ƒç”¨ IndexManager.rebuild

main æ–¹æ³•ï¼šnew CommandLine(new MainCommand()).execute(args)
ç”¨ emoji ç¾åŒ–è¾“å‡ºï¼ˆğŸ” ğŸ” âœ… âŒ âš ï¸ ğŸ“Šï¼‰
logback.xml: æ§åˆ¶å° + æ»šåŠ¨æ–‡ä»¶(10MB/ä»½, 7å¤©ä¿ç•™, 100MBä¸Šé™)
```

---

## Phase 5: æ®µåˆå¹¶ä¸å¢é‡

### Prompt 5.1
```
åœ¨ IndexManager ä¸­å®ç°ï¼š

1. æ®µåˆå¹¶ (mergeSegments)ï¼š
   - é€‰æ‹©åŒå±‚ â‰¥ MERGE_FACTOR (10) ä¸ªæ®µ
   - å¤šè·¯å½’å¹¶ï¼šéå†æ‰€æœ‰æ®µçš„ DictionaryReader.allTerms()ï¼ŒæŒ‰å­—å…¸åºåˆå¹¶
   - å¯¹æ¯ä¸ª term åˆå¹¶ PostingListï¼ˆè·³è¿‡ deletedDocIdsï¼‰
   - å†™å…¥æ–°æ®µ â†’ æ›´æ–° segments.gen â†’ æ ‡è®°æ—§æ®µ DELETED â†’ æ¸…ç†æ–‡ä»¶

2. å¢é‡æ›´æ–° (incrementalUpdate)ï¼š
   - FileCollector æ”¶é›†å…¨éƒ¨æ–‡ä»¶ â†’ ä¸ DocumentTable å¯¹æ¯”
   - mtime æˆ– size å˜åŒ– â†’ WAL.appendUpdate â†’ åˆ æ—§ + é‡ç´¢å¼•
   - æ–°æ–‡ä»¶ â†’ WAL.appendAdd â†’ ç´¢å¼•
   - ç¼ºå¤±æ–‡ä»¶ â†’ WAL.appendDelete â†’ æ ‡è®°åˆ é™¤

3. æ–‡ä»¶ç›‘æ§ (å¯é€‰)ï¼š
   - WatchService æ³¨å†Œæºç›®å½•
   - ENTRY_CREATE/MODIFY/DELETE â†’ å»æŠ–åŠ¨(500ms) â†’ å¢é‡æ›´æ–°
```

---

## Phase 6: æµ‹è¯•ä¸åŸºå‡†

### Prompt 6.1
```
è¡¥å……æµ‹è¯•ï¼š

1. é›†æˆæµ‹è¯• IndexIntegrationTestï¼š
   - setUp: åˆ›å»ºä¸´æ—¶ç›®å½•ï¼Œå†™å…¥ 50 ä¸ªæµ‹è¯•æ–‡ä»¶ï¼ˆ.md/.java/.txtï¼Œå«ä¸­è‹±æ–‡æ··åˆå†…å®¹ï¼‰
   - æµ‹è¯•å…¨é‡ç´¢å¼• â†’ search å‘½ä¸­ â†’ éªŒè¯ snippet åŒ…å«æŸ¥è¯¢è¯
   - æµ‹è¯•å¢é‡æ›´æ–°ï¼šä¿®æ”¹æ–‡ä»¶ â†’ é‡ç´¢å¼• â†’ éªŒè¯ç»“æœå˜åŒ–
   - æµ‹è¯•å´©æºƒæ¢å¤ï¼šç´¢å¼•ä¸­é€”å¼ºåˆ¶ä¸­æ–­ â†’ recoverFromWal â†’ éªŒè¯æ•°æ®ä¸€è‡´
   - æµ‹è¯•å­—æ®µè¿‡æ»¤ï¼šext:md, type:note, mtime èŒƒå›´
   - æµ‹è¯•çŸ­è¯­æŸ¥è¯¢ï¼šéªŒè¯ä½ç½®ç›¸é‚»æ€§

2. JMH åŸºå‡† IndexBenchmarkï¼š
   - indexThroughput: æµ‹é‡ 10K æ–‡ä»¶/ç§’
   - queryLatency: æµ‹é‡å•æ¬¡æŸ¥è¯¢ P99

ç›®æ ‡è¦†ç›–ç‡ â‰¥ 80%ã€‚
```
